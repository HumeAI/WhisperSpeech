# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/Reset Lightning training-Copy1.ipynb.

# %% auto 0
__all__ = []

# %% ../nbs/Reset Lightning training-Copy1.ipynb 1
import torch
from fastcore.script import call_parse

# %% ../nbs/Reset Lightning training-Copy1.ipynb 10
@call_parse
def main(ckpt:str, new_iters:int = None):
    spec = torch.load(ckpt, map_location='cpu')
    warmup_lr = spec['lr_schedulers'][0]['_schedulers'][0]    
    lr_step = spec['lr_schedulers'][0]['_schedulers'][1]['milestones']
    print(spec['lr_schedulers'][0]['_schedulers'])
    decay_step = sorted(lr_step.elements())[0]
    print(f"Current decay step: {decay_step} (guessing total iters: {(decay_step + warmup_lr['total_iters'])/0.9})")
    if new_iters:
        new_decay_step = new_iters * 0.9 - warmup_lr['total_iters']
        lr_step.clear()
        lr_step[new_decay_step] = 1
        print(f"New decay step: {sorted(lr_step.elements())[0]} (for a est. total of: {new_iters})")
        torch.save(spec, ckpt + '.new')
