# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/3A. Accent extraction.ipynb.

# %% auto 0
__all__ = []

# %% ../nbs/3A. Accent extraction.ipynb 2
import sys
import os
import itertools
import math
import random
from pathlib import Path

import numpy as np
import torch
import torch.nn.functional as F

from fastprogress import progress_bar
from fastcore.script import *

from . import utils, vad_merge
import webdataset as wds

import torchaudio
# requires 0.5.16, does not work with 1.0.0
from speechbrain.pretrained.interfaces import foreign_class

from .inference import get_compute_device

# %% ../nbs/3A. Accent extraction.ipynb 4
@call_parse
def prepare_accents(
    input:str,          # input shard URL/path
    output:str,         # output shard URL/path
    n_samples:int=None, # process a limited amount of samples
    batch_size:int=8, # process several segments at once
    kind:str="raw"
):
    Path('_cache').mkdir(exist_ok=True)
    import math, time
    start = time.time()
    ds = wds.WebDataset([utils.derived_name(input, 'mvad')]).decode()
    total = math.ceil(sum([len(x[f'{kind}.spk_emb.npy']) for x in ds])/batch_size)
    print(f"Counting {total} batches: {time.time()-start:.2f}")
    
    print(f"CUDA: {torch.cuda.is_available()}  {torch.cuda.device_count()} GPUs, GPU0: {torch.cuda.get_device_name(0)}")
        
    classifier = foreign_class(source="Jzuluaga/accent-id-commonaccent_xlsr-en-english",
                               pymodule_file="custom_interface.py",
                               classname="CustomEncoderWav2vec2Classifier",
                               run_opts = {"device": 'cuda'})

    ds = vad_merge.chunked_audio_dataset([input], kind).compose(
        utils.resampler(16000, 'samples_16k'),
        wds.to_tuple('__key__', 'rpad_s', 'samples_16k'),
        wds.batched(512),
    )
    
    dl = wds.WebLoader(ds, num_workers=1, batch_size=None).unbatched().batched(batch_size)

    if n_samples:
        print(f"Benchmarking run of {n_samples} samples ({n_samples//batch_size} batches)")
        dl = dl.slice(n_samples//batch_size)
    
    with utils.AtomicTarWriter(output, throwaway=n_samples is not None) as sink:
        for keys, rpad_ss, audios in progress_bar(dl, total=total):
            probss, scores, _, labels = classifier.classify_batch(audios, wav_lens=torch.tensor(30 - rpad_ss, dtype=torch.float)/30)

            for key, probs, label in zip(keys, probss, labels):
                sink.write({
                    "__key__": key,
                    "probs.npy": probs.cpu().numpy(),
                    "accent.txt": label,
                })
        sys.stdout.write('\n')
